{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BCytHvI-lw51"
      },
      "outputs": [],
      "source": [
        "# Simple Transformer using PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Toy data generation\n",
        "vocab_size= 100\n",
        "seq_length=10\n",
        "batch_size=32\n",
        "\n",
        "X=torch.randint(0, vocab_size, (batch_size, seq_length)).to(device)\n",
        "Y= X.clone().to(device)"
      ],
      "metadata": {
        "id": "DHr8BQ_ll_m5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrdco_UqmUJm",
        "outputId": "7185ed41-4a59-4852-e211-a445f7157db8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P82tRtzKmXlJ",
        "outputId": "1db5fb27-c157-4391-f958-de9e9ffa51b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yyJbxIUmYau",
        "outputId": "f4b0888b-a9ac-484b-9119-225a91b06a94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([24, 12, 79, 22, 66, 55, 90, 40, 36, 68])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim,num_heads, num_layers, ff_dim, max_len=100):\n",
        "    super().__init__()\n",
        "    self.embedding= nn.Embedding(vocab_size, embed_dim)\n",
        "    self.pos_encoding= nn.Parameter(torch.zeros(1,max_len, embed_dim))\n",
        "\n",
        "    # Encoder + Decoder\n",
        "    self.transformer= nn.Transformer(\n",
        "        d_model=embed_dim,\n",
        "        nhead=num_heads,\n",
        "        num_encoder_layers=num_layers,\n",
        "        num_decoder_layers=num_layers,\n",
        "        dim_feedforward=ff_dim,\n",
        "        dropout=0.1,\n",
        "        batch_first=True\n",
        "\n",
        "    )\n",
        "    self.fc_out= nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    #src and tgt [bacth, seq_len]\n",
        "    src_emb= self.embedding(src) + self.pos_encoding[:, :src.size(1), :]\n",
        "    tgt_emb= self.embedding(tgt) + self.pos_encoding[:, : tgt.size(1), :]\n",
        "\n",
        "    out= self.transformer(src_emb, tgt_emb)\n",
        "    return self.fc_out(out)\n"
      ],
      "metadata": {
        "id": "fx8Q1V-fmZHY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "model= TransformerModel(\n",
        "    vocab_size= vocab_size,\n",
        "    embed_dim=64,\n",
        "    num_heads=4,\n",
        "    num_layers=2,\n",
        "    ff_dim=2048\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "DA-cfB-en8Wl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer= optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "1TzsRuPZoQHd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  output= model(X,Y[:,:-1])\n",
        "  loss= criterion(output.reshape(-1, vocab_size),Y[:,1:].reshape(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}. loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xy6LTTZokA3",
        "outputId": "1660aede-f221-4991-cb0b-9c994012e880"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1. loss: 4.8237\n",
            "Epoch 2. loss: 4.4637\n",
            "Epoch 3. loss: 4.2098\n",
            "Epoch 4. loss: 3.9642\n",
            "Epoch 5. loss: 3.7837\n",
            "Epoch 6. loss: 3.6050\n",
            "Epoch 7. loss: 3.4409\n",
            "Epoch 8. loss: 3.3192\n",
            "Epoch 9. loss: 3.1858\n",
            "Epoch 10. loss: 3.0709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference Demo\n",
        "test_seq= torch.randint(0, vocab_size, (1,seq_length)).to(device)\n",
        "print(\"Input IDs:\", test_seq)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred= model(test_seq, test_seq[:,:-1])\n",
        "    predicted_tokens= pred.argmax(dim=-1)\n",
        "    print(\"predicted IDs:\", predicted_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNzcHR7FpLPQ",
        "outputId": "cb4e2e4a-4e73-4a68-909d-8fbe8f01bdfb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[77, 36, 12, 85, 40, 65, 19, 85, 23, 51]])\n",
            "predicted IDs: tensor([[ 1, 90, 68, 74, 36, 55, 83, 74, 36]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r21fEk5IqMnE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}